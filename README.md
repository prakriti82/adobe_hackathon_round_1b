# Adobe Connecting the Dots â€“ Round 1B Submission
ğŸ¯ Problem Statement: Persona-driven Document Intelligence The objective of Round 1B is to develop a system that can provide persona-driven content recommendations from research papers. Given a research paper and a target persona (e.g., high school student, policy-maker, graduate researcher), the system must extract relevant information and generate a concise, persona-specific summary.

# ğŸ› ï¸ Solution Overview We created a persona-aware PDF summarization engine that:

Parses the document into manageable chunks. Generates embeddings using the all-MiniLM-L6-v2 SentenceTransformer. Accepts a persona query. Ranks and selects the most relevant text spans. Returns a condensed summary tailored to the input persona. This solution is containerized using Docker for cross-platform portability.

ğŸ“‚ Project Structure round1b/ â”‚ â”œâ”€â”€ input/ # Folder containing the input PDF â”‚ â””â”€â”€ research_paper.pdf â”‚ â”œâ”€â”€ output/ # Folder where persona-specific summary is saved â”‚ â””â”€â”€ research_paper_summary.txt â”‚ â”œâ”€â”€ model/ # Pre-downloaded SentenceTransformer model â”‚ â””â”€â”€ all-MiniLM-L6-v2/ â”‚ â”œâ”€â”€ main.py # Main pipeline script â”œâ”€â”€ save_model.py # Script to download & save the embedding model â”œâ”€â”€ requirements.txt # Python package dependencies â”œâ”€â”€ Dockerfile # Docker container definition â””â”€â”€ README.md # Project documentation

yaml Copy Edit

# ğŸš€ How to Run (Locally)

âœ… Install Dependencies in a Virtual Environment python -m venv venv source venv/bin/activate # or venv\Scripts\activate on Windows pip install -r requirements.txt ğŸ“¥ Download the SentenceTransformer Model python save_model.py This will create the folder model/all-MiniLM-L6-v2 with the necessary weights.
ğŸ§ª Run the Summarization Script Ensure a .pdf file is in the input/ directory. Then run: python main.py The persona query will be prompted via the terminal.

Output will be saved in the output/ folder as a .txt file.

# ğŸ³ Run with Docker

Build the Docker Image docker build -t round1b-extractor . Run the Container docker run --rm
-v "$(pwd)/input:/app/input"
-v "$(pwd)/output:/app/output"
-v "$(pwd)/model:/app/model"
--network host
# round1b-extractor ğŸªŸ For Windows PowerShell Users:

docker run --rm -v "${PWD}/input:/app/input" -v "${PWD}/output:/app/output" -v "${PWD}/model:/app/model" --network host ` round1b-extractor ğŸ§  How It Works Chunking: Break the PDF into small paragraph segments.

Embedding: Encode each chunk and persona query using the all-MiniLM-L6-v2 model.

Similarity Matching: Rank chunks by cosine similarity.

Summary Generation: Return top N segments as a tailored summary.

# ğŸ“Œ Dependencies sentence-transformers

PyMuPDF

torch

numpy

ğŸ“‹ See requirements.txt for exact versions.

ğŸ“¥ Sample Output Input: research_paper.pdf Persona: "Explain this paper to a high school student."

# Output:

output/research_paper_summary.txt Sample contents:

arduino Copy Edit This research explores the use of AI in understanding human language. It teaches computers to read and find important patterns in text... ğŸ§ª Evaluation Criteria âœ… Persona relevance and clarity of summary

âœ… Ability to extract useful context from complex research papers

âœ… Accuracy and fluency of generated content

ğŸ‘¨â€ğŸ’» Author Built with â¤ï¸ by Ashutosh Bhardwaj for the Adobe Connecting the Dots Challenge â€“ Round 1B
